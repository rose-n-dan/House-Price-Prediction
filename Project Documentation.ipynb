{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predykcja cen nieruchomości oparta na modelu maszyny wektorów nośnych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstęp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokumentacja będzie skupiała się na rozwiązaniu problemu przewidywania cen nieruchomości z perspektywy potencjalnego kupującego oraz sprzedającego\n",
    "\n",
    "\n",
    "A house value is simply more than location and square footage. Like the features that make up a person, an educated party would want to know all aspects that give a house its value.\n",
    "\n",
    "We are going to take advantage of all of the feature variables available to use and use it to analyze and predict house prices.\n",
    "\n",
    "We are going to break everything into logical steps that allow us to ensure the cleanest, most realistic data for our model to make accurate predictions from.\n",
    "\n",
    "1. Load Data and Packages\n",
    "2. Analyzing the Test Variable (Sale Price)\n",
    "3. Multivariable Analysis\n",
    "4. Impute Missing Data and Clean Data\n",
    "5. Feature Transformation/Engineering\n",
    "6. Modeling and Predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "#import xgboost as xgb\n",
    "#import lightgbm as lgb\n",
    "from scipy.stats import skew\n",
    "from scipy import stats\n",
    "from scipy.stats.stats import pearsonr\n",
    "from scipy.stats import norm\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LinearRegression,LassoCV, Ridge, LassoLarsCV,ElasticNetCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, RobustScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "%config InlineBackend.figure_format = 'retina' #set 'png' here when working on notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and Test set\n",
    "train = pd.read_csv(\"./boston-housing/train.csv\")\n",
    "test = pd.read_csv(\"./boston-housing/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the numbers of samples and features\n",
    "print(\"The train data size before dropping Id feature is : {} \".format(train.shape))\n",
    "print(\"The test data size before dropping Id feature is : {} \".format(test.shape))\n",
    "\n",
    "# Save the 'Id' column\n",
    "train_ID = train['ID']\n",
    "test_ID = test['ID']\n",
    "\n",
    "# Now drop the 'Id' column since it's unnecessary for the prediction process.\n",
    "train.drop(\"ID\", axis = 1, inplace = True)\n",
    "test.drop(\"ID\", axis = 1, inplace = True)\n",
    "\n",
    "# Check data size after dropping the 'Id' variable\n",
    "print(\"\\nThe train data size after dropping Id feature is : {} \".format(train.shape)) \n",
    "print(\"The test data size after dropping Id feature is : {} \".format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Description\n",
    "train['medv'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histogram\n",
    "sns.distplot(train['medv'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['medv'])\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Median Value distribution')\n",
    "\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['medv'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "print(\"Skewness: %f\" % train['medv'].skew())\n",
    "print(\"Kurtosis: %f\" % train['medv'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multivariable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix Heatmap\n",
    "corrmat = train.corr()\n",
    "f, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.heatmap(corrmat, vmin=-1, vmax=1, square=True, center=0, annot=True, fmt='.2f');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = corrmat.abs().nlargest(14, 'medv')['medv'].index\n",
    "most_corr = pd.DataFrame(cols)\n",
    "most_corr.columns = ['Most Correlated Features']\n",
    "most_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BLACKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train['black'], y=train['medv'], kind='reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'black'\n",
    "data = pd.concat([train['medv'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(25, 12))\n",
    "fig = sns.boxplot(x=var, y=\"medv\", data=data)\n",
    "fig.axis(ymin=0, ymax=52);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F A T A L N E** dane "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwamy je\n",
    "train.drop(['black'], axis=1, inplace=True)\n",
    "test.drop(['black'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwamy też rzekę - też lipna\n",
    "train.drop(['chas'], axis=1, inplace=True)\n",
    "test.drop(['chas'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dane o najwyższej wartości bezwzględnej korelacji**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train['lstat'], y=train['medv'], kind='reg');\n",
    "print(train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers manually \n",
    "train = train.drop(train[(train['medv']>49.99) & (train['lstat']>8)].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train['lstat'], y=train['medv'], kind='reg');\n",
    "print(pearsonr(train['lstat'], train['medv']));\n",
    "print(train.shape[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train['rm'], y=train['medv'], kind='reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiekość pokoi może być różna - nie odrzucamy tu obserwacji odstających\n",
    "# train = train.drop(train[(train['medv'] > 8 * train['rm'] - 8)].index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.jointplot(x=train['rm'], y=train['medv'], kind='reg');\n",
    "# print(pearsonr(train['rm'], train['medv']));\n",
    "# print(train.shape[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train['ptratio'], y=train['medv'], kind='reg');\n",
    "# w jednym mieście może być wiele regionów o różnej charakterystyce; \n",
    "# współczynnik ptratio jest wspólny dla wszystkich regionów miasta - biednych i bogatych\n",
    "# jednak można zauważyć silną ujemną korelację miedzy tymi wielkościami\n",
    "# ciężko cokolwiek odrzucić"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'ptratio'\n",
    "data = pd.concat([train['medv'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(25, 12))\n",
    "fig = sns.boxplot(x=var, y=\"medv\", data=data)\n",
    "fig.axis(ymin=0, ymax=52);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train['indus'], y=train['medv'], kind='reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'indus'\n",
    "data = pd.concat([train['medv'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(25, 12))\n",
    "fig = sns.boxplot(x=var, y=\"medv\", data=data)\n",
    "fig.axis(ymin=0, ymax=52);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=train['tax'], y=train['medv'], kind='reg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'tax'\n",
    "data = pd.concat([train['medv'], train[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(25, 12))\n",
    "fig = sns.boxplot(x=var, y=\"medv\", data=data)\n",
    "fig.axis(ymin=0, ymax=52);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uzupełnianie danych - nasze dane są kompletne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "train[\"medv\"] = np.log1p(train[\"medv\"])\n",
    "\n",
    "#Check the new distribution \n",
    "sns.distplot(train['medv'] , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(train['medv'])\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(train['medv'], plot=plt)\n",
    "plt.show()\n",
    "\n",
    "y_train = train.medv.values\n",
    "\n",
    "print(\"Skewness: %f\" % train['medv'].skew())\n",
    "print(\"Kurtosis: %f\" % train['medv'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['medv'], axis=1, inplace=True)\n",
    "print(\"Train data size is : {}\".format(train.shape))\n",
    "print(\"Test data size is : {}\".format(test.shape))\n",
    "print(\"Combined dataset size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: (skew(x.dropna()))).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Positive skewed Features' :skewed_feats})\n",
    "skewness.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewness = skewness[skewness > 0.8]\n",
    "# print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "skewness = skewness[skewness > 0.8]\n",
    "skewness = skewness.dropna()\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    all_data[feat] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data[numeric_feats].apply(lambda x: (skew(x.dropna()))).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Positive skewed Features' :skewed_feats})\n",
    "skewness.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = all_data[:ntrain]\n",
    "test = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
